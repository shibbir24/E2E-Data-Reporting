{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation on the Address table (example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbutils.fs.ls('mnt/silver/SalesLT/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbutils.fs.ls('mnt/gold/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_path = '/mnt/silver/SalesLT/Address/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the PySpark data frame\n",
    "#format given as delta since the data frame was written as such in the silver container. need to specify the same format here as well.\n",
    "\n",
    "# df = spark.read.format('delta').load(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "# from pyspark.sql.functions import col, regexp_replace\n",
    "\n",
    "#Get the list of column names\n",
    "# column_names = df.columns\n",
    "\n",
    "# for old_col_name in column_names:\n",
    "    #Convert column names from ColumnName to Column_Name format\n",
    "#    new_col_name = \"\".join([\"_\" + char if char.isupper() and not old_col_name[i - 1].isupper() else char for i, char in enumerate(old_col_name)]).lstrip(\"_\")\n",
    "    \n",
    "    #Change the column name using withColumnRenamed and regexp_replace\n",
    " #   df = df.withColumnRenamed(old_col_name, new_col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation for all tables (change column name format from ColumnName to Column_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = []\n",
    "\n",
    "# populate table_name with all available tables from the silver container\n",
    "for i in dbutils.fs.ls('mnt/silver/SalesLT/'):\n",
    "    table_name.append(i.name.split('/')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate through the table_name list and perform the transformations on all the individual tables\n",
    "\n",
    "#Generate the input path using a for each loop\n",
    "for name in table_name:\n",
    "    path = '/mnt/silver/SalesLT/' + name\n",
    "    print(path)\n",
    "    #read as a data frame using delta format\n",
    "    df = spark.read.format('delta').load(path)\n",
    "    \n",
    "    #Get the list of column names\n",
    "    column_names = df.columns\n",
    "\n",
    "    for old_col_name in column_names:\n",
    "        #Convert column name from ColumnName to Column_Name\n",
    "        new_col_name = \"\".join([\"_\" + char if char.isupper() and not old_col_name[i - 1].isupper() else char for i, char in enumerate(old_col_name)]).lstrip(\"_\")\n",
    "    \n",
    "        #Change the column name using withColumnRenamed and regexp_replace\n",
    "        df = df.withColumnRenamed(old_col_name, new_col_name)\n",
    "\n",
    "    #Use the data frame to convert all the column names to the expected format\n",
    "    output_path = '/mnt/gold/SalesLT/' + name + '/'\n",
    "    df.write.format('delta').mode(\"overwrite\").save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displays the last item in the table_name list which is SalesOrderHeader\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
